# 实验方法设置

## 1. 整体架构

本文提出 SKA-VCT (Spectral-Kinematic Alignment for Vision-Centric Transformer)，基于 Vision-Centric Transformer (VCT) 框架进行音频-视觉语义分割任务。整体架构包括：

- **视觉编码器**: Swin-B Transformer 作为骨干网络，提取多尺度视觉特征
- **音频编码器**: VGGish 网络提取音频特征，维度为 512×6×4
- **像素解码器**: MSDeformAttnPixelDecoder，输出高分辨率 mask features (256×56×56)
- **Transformer 解码器**: MultiScaleMaskedVCTDecoder，包含 10 层解码器
- **创新模块**: 
  - SKA (Spectral-Kinematic Alignment) 模块：频谱-运动对齐
  - BRM (Boundary Refinement Module) 模块：边界细化

## 2. Spectral-Kinematic Alignment (SKA) 模块

### 2.1 动机

传统光流图包含大量噪声，例如被风吹动的叶子等不发声的运动物体。SKA 模块利用音频频谱特征作为查询，对运动学（光流）特征进行注意力计算，生成仅激活"既运动又发声"区域的权重图。通过频谱-运动对齐，有效过滤无关运动噪声，提升分割精度。

### 2.2 架构设计

SKA 模块采用交叉注意力机制，具体包括：

1. **光流编码器 (Flow Encoder)**: 将光流图编码到特征空间
   - 输入: 光流图 $M \in \mathbb{R}^{B \times C_{flow} \times H \times W}$，其中 $C_{flow}=1$（单通道光流幅值）
   - 编码过程:
     $$
     F_{flow} = \text{BN}(\text{Conv2d}(M, 64, 3×3)) \rightarrow \text{ReLU} \rightarrow \text{BN}(\text{Conv2d}(64, d_{emb}, 1×1))
     $$
   - 输出: $F_{flow} \in \mathbb{R}^{B \times d_{emb} \times H \times W}$，其中 $d_{emb}=256$

2. **音频投影 (Audio Projection)**: 将音频特征投影到相同维度
   - 输入: 音频特征 $A \in \mathbb{R}^{B \times C_{audio}}$，其中 $C_{audio}=256$（经过全局平均池化后的音频特征）
   - 投影过程:
     $$
     A_{proj} = \text{LayerNorm}(\text{Linear}(A, d_{emb}))
     $$
   - 输出: $A_{proj} \in \mathbb{R}^{B \times d_{emb}}$

3. **交叉注意力计算 (Cross-Attention)**:
   - Query (Q) 来自音频特征，Key (K) 和 Value (V) 来自光流特征
   - 计算过程:
     $$
     Q = W_q \cdot A_{proj} \in \mathbb{R}^{B \times 1 \times d_{emb}}
     $$
     $$
     K = W_k \cdot F_{flow}^{flat} \in \mathbb{R}^{B \times HW \times d_{emb}}
     $$
     $$
     V = W_v \cdot F_{flow}^{flat} \in \mathbb{R}^{B \times HW \times d_{emb}}
     $$
   其中 $F_{flow}^{flat} \in \mathbb{R}^{B \times HW \times d_{emb}}$ 是将 $F_{flow}$ 展平后的特征。

4. **多头注意力 (Multi-Head Attention)**:
   - 将 Q, K, V 重塑为多头形式:
     $$
     Q_h = \text{Reshape}(Q, [B, H_{heads}, 1, d_{head}])
     $$
     $$
     K_h = \text{Reshape}(K, [B, H_{heads}, HW, d_{head}])
     $$
     $$
     V_h = \text{Reshape}(V, [B, H_{heads}, HW, d_{head}])
     $$
   其中 $H_{heads}=4$，$d_{head}=d_{emb}/H_{heads}=64$。

5. **缩放点积注意力 (Scaled Dot-Product Attention)**:
   - 使用可学习的温度参数 $\tau$ 控制注意力锐度:
     $$
     \text{Attn} = \text{Softmax}\left(\frac{Q_h K_h^T}{\sqrt{d_{head}} \cdot \tau}\right) \in \mathbb{R}^{B \times H_{heads} \times 1 \times HW}
     $$
   - 加权求和:
     $$
     \text{AttnOutput} = \text{Attn} \cdot V_h \in \mathbb{R}^{B \times H_{heads} \times 1 \times d_{head}}
     $$

6. **空间注意力图生成**:
   - 对多头注意力权重进行平均:
     $$
     \text{SpatialAttn} = \frac{1}{H_{heads}} \sum_{h=1}^{H_{heads}} \text{Attn}_h \in \mathbb{R}^{B \times 1 \times HW}
     $$
   - 重塑为空间维度:
     $$
     \text{SpatialAttn} = \text{Reshape}(\text{SpatialAttn}, [B, 1, H, W])
     $$

7. **归一化**:
   - 使用 min-max 归一化将注意力图归一化到 [0, 1] 范围:
     $$
     M_{weight} = \frac{\text{SpatialAttn} - \min(\text{SpatialAttn})}{\max(\text{SpatialAttn}) - \min(\text{SpatialAttn}) + \epsilon}
     $$
   其中 $\epsilon=10^{-8}$ 防止除零。

### 2.3 实现细节

- **输入尺寸**: 光流图首先下采样到 24×24 以降低计算复杂度
- **输出**: 音频激活的运动权重图 $M_{weight} \in \mathbb{R}^{B \times 1 \times H \times W}$，值域 [0, 1]
- **上采样**: 将权重图上采样回 mask features 的分辨率 (56×56)

### 2.4 公式总结

完整的 SKA 模块计算流程可表示为：

$$
M_{weight} = \text{Normalize}\left(\text{Mean}\left(\text{Softmax}\left(\frac{Q K^T}{\sqrt{d_{head}} \cdot \tau}\right)\right)\right)
$$

其中 $Q = W_q \cdot \text{LayerNorm}(\text{Linear}(A))$ 来自音频频谱特征，$K = W_k \cdot \text{Encoder}(M)$ 来自运动学（光流）特征。该公式实现了频谱特征与运动学特征的对齐，生成音频激活的运动权重图。

## 3. Boundary Refinement Module (BRM) 模块

### 3.1 动机

光流边界模糊会导致 F-score 下降。BRM 模块通过边界预测作为辅助监督任务，强制网络关注细粒度边界信息。

### 3.2 架构设计

BRM 模块包括两个主要组件：

1. **边界预测分支 (Boundary Branch)**:
   - 输入: 高分辨率 mask features $F_{mask} \in \mathbb{R}^{B \times 256 \times 56 \times 56}$
   - 架构: 轻量级 FCN 结构
     $$
     F_{boundary} = \text{BN}(\text{Conv2d}(F_{mask}, 128, 3×3)) \rightarrow \text{ReLU} \rightarrow \text{Conv2d}(128, 1, 1×1)
     $$
   - 输出: 边界预测 logits $P_{boundary} \in \mathbb{R}^{B \times 1 \times 56 \times 56}$

2. **边界真值生成 (Boundary GT Generation)**:
   - 从分割 mask GT 动态生成边界真值
   - 算法: 使用形态学操作
     $$
     \text{Dilated} = \text{MaxPool}(M_{gt}, k=3)
     $$
     $$
     \text{Eroded} = -\text{MaxPool}(-M_{gt}, k=3)
     $$
     $$
     B_{gt} = \text{Clamp}(\text{Dilated} - \text{Eroded}, 0, 1)
     $$
   其中 $M_{gt} \in \mathbb{R}^{B \times H \times W}$ 是分割 mask 真值。

### 3.3 边界损失函数

使用带权重的二元交叉熵损失 (Weighted BCE Loss):

$$
\mathcal{L}_{boundary} = \text{BCEWithLogits}(P_{boundary}, B_{gt}, \text{pos\_weight}=\alpha)
$$

其中 $\alpha=5.0$ 用于平衡正负样本（边界像素通常远少于非边界像素）。

### 3.4 总损失函数

边界损失与主分割损失结合：

$$
\mathcal{L}_{total} = \mathcal{L}_{seg} + \lambda_{boundary} \cdot \mathcal{L}_{boundary}
$$

其中 $\lambda_{boundary}=0.5$ 是边界损失的权重。

## 4. 损失函数

### 4.1 主分割损失

采用 Mask2Former 的标准损失函数组合：

1. **分类损失 (Classification Loss)**:
   $$
   \mathcal{L}_{cls} = \text{CrossEntropy}(\hat{y}, y)
   $$
   权重: $w_{cls} = 2.0$

2. **Mask 损失 (Mask Loss)**:
   $$
   \mathcal{L}_{mask} = \text{BCE}(\hat{M}, M_{gt})
   $$
   权重: $w_{mask} = 5.0$

3. **Dice 损失 (Dice Loss)**:
   $$
   \mathcal{L}_{dice} = 1 - \frac{2|\hat{M} \cap M_{gt}|}{|\hat{M}| + |M_{gt}|}
   $$
   权重: $w_{dice} = 5.0$

4. **原型损失 (Prototype Loss)**:
   $$
   \mathcal{L}_{proto} = \text{PrototypeLoss}(\hat{M}, M_{gt})
   $$
   权重: $w_{proto} = 1.0$

### 4.2 总损失

$$
\mathcal{L}_{total} = w_{cls} \cdot \mathcal{L}_{cls} + w_{mask} \cdot \mathcal{L}_{mask} + w_{dice} \cdot \mathcal{L}_{dice} + w_{proto} \cdot \mathcal{L}_{proto} + \lambda_{boundary} \cdot \mathcal{L}_{boundary}
$$

## 5. 训练配置

### 5.1 数据集

- **数据集**: AVSBench_semantic
- **训练集**: 7948 个视频
  - v1m: 296 个视频
  - v1s: 3452 个视频
  - v2: 4200 个视频
- **验证集**: 1704 个视频
- **测试集**: 1704 个视频
- **类别数**: 71 个语义类别

### 5.2 训练超参数

- **Batch Size**: 2（受显存限制，v2 数据有 10 帧）
- **学习率**: 0.0001
- **最大迭代次数**: 90000
- **优化器**: AdamW
- **学习率调度**: 多项式衰减
- **混合精度训练 (AMP)**: 启用
- **图像尺寸**: 384×384
- **随机种子**: 8434882

### 5.3 数据预处理

1. **图像预处理**:
   - 训练时: 使用原始 `frames` 目录，实时 resize 到 384×384
   - 测试时: 使用预处理后的 `processed_frames_384` 目录
   - 归一化: ImageNet 均值和标准差

2. **音频预处理**:
   - 提取 log-mel 频谱图: 96×64
   - 使用 VGGish 提取特征: 512×6×4

3. **光流预处理**:
   - 使用 RAFT 算法计算光流
   - 提取光流幅值图: 单通道
   - 下采样到 24×24 用于 SKA 模块

4. **预训练 SAM mask**:
   - 使用 SemanticSAM 生成初始 mask
   - 转换为非重叠的彩色 mask
   - Resize 到 384×384

### 5.4 模型配置

- **骨干网络**: Swin-B (ImageNet-22k 预训练)
- **隐藏维度**: 256
- **查询数量**: 100
- **解码器层数**: 10
- **注意力头数**: 8
- **Dropout**: 0.0
- **前馈网络维度**: 2048

### 5.5 创新模块配置

- **SKA 模块**:
  - 音频维度: 256
  - 嵌入维度: 256
  - 注意力头数: 4
  - Dropout: 0.0

- **BRM 模块**:
  - 输入通道: 256
  - 隐藏通道: 128
  - 边界损失权重: 0.5
  - 正样本权重: 5.0

## 6. 评估指标

- **mIoU (mean Intersection over Union)**: 平均交并比
  $$
  \text{mIoU} = \frac{1}{C} \sum_{c=1}^{C} \frac{|\hat{M}_c \cap M_{gt,c}|}{|\hat{M}_c \cup M_{gt,c}|}
  $$

- **F-Score**: F1 分数
  $$
  F = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
  $$

## 7. 实现细节

### 7.1 训练流程

1. 加载图像、音频和光流数据
2. 提取视觉特征（Swin-B backbone）
3. 提取音频频谱特征（VGGish backbone）
4. 计算光流（如果启用 SKA）
5. 应用 SKA 模块生成频谱-运动对齐的权重图
6. 通过像素解码器生成 mask features
7. 通过 Transformer 解码器生成分割预测
8. 应用 BRM 模块生成边界预测
9. 计算总损失并反向传播

### 7.2 推理流程

1. 加载测试图像和音频
2. 提取特征（同训练流程）
3. 生成分割预测
4. 后处理（resize 到原始尺寸）
5. 计算评估指标

### 7.3 关键技术点

- **Batch Size 对齐**: 由于 `FILTER_EMPTY_ANNOTATIONS=True` 会过滤空标注，需要确保 `pred_boundary` 和 `targets` 的 batch size 一致
- **特征尺寸对齐**: SKA 模块中光流图需要下采样到固定尺寸 (24×24)，然后上采样回 mask features 分辨率
- **频谱-运动对齐**: SKA 模块通过交叉注意力机制实现音频频谱特征与运动学特征的对齐，有效过滤无关运动噪声
- **边界真值生成**: 使用形态学操作（膨胀-腐蚀）从分割 mask 生成边界真值，避免需要额外的边界标注

## 8. 实验设置总结

| 配置项 | 值 |
|--------|-----|
| 数据集 | AVSBench_semantic (v1m + v1s + v2) |
| 训练视频数 | 7948 |
| 验证视频数 | 1704 |
| 测试视频数 | 1704 |
| 类别数 | 71 |
| Batch Size | 2 |
| 学习率 | 0.0001 |
| 最大迭代 | 90000 |
| 图像尺寸 | 384×384 |
| 骨干网络 | Swin-B |
| 查询数量 | 100 |
| 解码器层数 | 10 |
| SKA 模块 | 启用 |
| BRM 模块 | 启用 |
| 混合精度 | 启用 |

